{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fra.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining lists for store the samples\n",
    "en_samples,de_samples = [],[]\n",
    "#define sets to store the characters in them\n",
    "en_chars, de_chars = set(), set()\n",
    "\n",
    "# Split the samples and get the character sets :\n",
    "for line in text:\n",
    "    en_ , de_ = line.split('\\t')\n",
    "    de_ = '\\t' + de_\n",
    "    for char in de_:\n",
    "        if char not in de_chars:\n",
    "            de_chars.add(char)\n",
    "    for char in en_:\n",
    "        if char not in en_chars:\n",
    "            en_chars.add(char)\n",
    "    en_samples.append(en_)\n",
    "    de_samples.append(de_)\n",
    "   \n",
    "# Add the chars \\t and \\n to the sets \n",
    "de_chars.add('\\n')\n",
    "de_chars.add('\\t')\n",
    "\n",
    "en_chars.add('\\n')\n",
    "en_chars.add('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167130\n",
      "Go.\n"
     ]
    }
   ],
   "source": [
    "print(len(en_samples))\n",
    "print(en_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167130\n",
      "\tVa !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(de_samples))\n",
    "print(de_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'z', 'E', ':', 'q', '6', 'é', 'b', 'h', 'ç', '1', 'g', ',', '&', 'a', '4', 'l', 'c', 'I', 'e', '\"', 'K', 'o', 'w', 'H', 'i', '7', 'D', 'B', 'G', 'X', '%', ';', 'T', '€', 'а', '9', 'L', 'y', 'k', 't', 'V', 'v', '₂', 'C', '+', 'u', 'J', 'M', 'A', 'Q', 'p', 'S', '’', 'Z', 'Y', '\\xa0', '3', 'r', '\\xad', '/', '2', ' ', 'j', '\\t', 'N', 'ö', '‘', 'ú', 'n', '.', 'x', '-', 'º', '$', '0', 'd', 'U', '?', '5', '\\n', '—', 'F', 'm', '!', 's', \"'\", 'W', 'P', '8', '–', 'f', 'O', 'R'}\n"
     ]
    }
   ],
   "source": [
    "print(en_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the needed dictionaries to convert characters to integers and vise versa.....\n",
    "de_char_to_int, de_int_to_char , en_char_to_int, en_int_to_char = dict(), dict(), dict(), dict()\n",
    "for i, char in enumerate(en_chars):\n",
    "    en_char_to_int[char] = i\n",
    "    en_int_to_char[i] = char\n",
    "for j, char in enumerate(de_chars):\n",
    "    de_char_to_int[char] = j\n",
    "    de_int_to_char[j] = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'z': 0, 'E': 1, ':': 2, 'q': 3, '6': 4, 'é': 5, 'b': 6, 'h': 7, 'ç': 8, '1': 9, 'g': 10, ',': 11, '&': 12, 'a': 13, '4': 14, 'l': 15, 'c': 16, 'I': 17, 'e': 18, '\"': 19, 'K': 20, 'o': 21, 'w': 22, 'H': 23, 'i': 24, '7': 25, 'D': 26, 'B': 27, 'G': 28, 'X': 29, '%': 30, ';': 31, 'T': 32, '€': 33, 'а': 34, '9': 35, 'L': 36, 'y': 37, 'k': 38, 't': 39, 'V': 40, 'v': 41, '₂': 42, 'C': 43, '+': 44, 'u': 45, 'J': 46, 'M': 47, 'A': 48, 'Q': 49, 'p': 50, 'S': 51, '’': 52, 'Z': 53, 'Y': 54, '\\xa0': 55, '3': 56, 'r': 57, '\\xad': 58, '/': 59, '2': 60, ' ': 61, 'j': 62, '\\t': 63, 'N': 64, 'ö': 65, '‘': 66, 'ú': 67, 'n': 68, '.': 69, 'x': 70, '-': 71, 'º': 72, '$': 73, '0': 74, 'd': 75, 'U': 76, '?': 77, '5': 78, '\\n': 79, '—': 80, 'F': 81, 'm': 82, '!': 83, 's': 84, \"'\": 85, 'W': 86, 'P': 87, '8': 88, '–': 89, 'f': 90, 'O': 91, 'R': 92}\n"
     ]
    }
   ],
   "source": [
    "print(en_char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'z', 1: 'E', 2: ':', 3: 'q', 4: '6', 5: 'é', 6: 'b', 7: 'h', 8: 'ç', 9: '1', 10: 'g', 11: ',', 12: '&', 13: 'a', 14: '4', 15: 'l', 16: 'c', 17: 'I', 18: 'e', 19: '\"', 20: 'K', 21: 'o', 22: 'w', 23: 'H', 24: 'i', 25: '7', 26: 'D', 27: 'B', 28: 'G', 29: 'X', 30: '%', 31: ';', 32: 'T', 33: '€', 34: 'а', 35: '9', 36: 'L', 37: 'y', 38: 'k', 39: 't', 40: 'V', 41: 'v', 42: '₂', 43: 'C', 44: '+', 45: 'u', 46: 'J', 47: 'M', 48: 'A', 49: 'Q', 50: 'p', 51: 'S', 52: '’', 53: 'Z', 54: 'Y', 55: '\\xa0', 56: '3', 57: 'r', 58: '\\xad', 59: '/', 60: '2', 61: ' ', 62: 'j', 63: '\\t', 64: 'N', 65: 'ö', 66: '‘', 67: 'ú', 68: 'n', 69: '.', 70: 'x', 71: '-', 72: 'º', 73: '$', 74: '0', 75: 'd', 76: 'U', 77: '?', 78: '5', 79: '\\n', 80: '—', 81: 'F', 82: 'm', 83: '!', 84: 's', 85: \"'\", 86: 'W', 87: 'P', 88: '8', 89: '–', 90: 'f', 91: 'O', 92: 'R'}\n"
     ]
    }
   ],
   "source": [
    "print(en_int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prabha Number of Encoder samples \t : 167130\n",
      "Prabha Number of Decoder samples \t : 167130\n",
      "Number of Encoder chars \t : 93\n",
      "Number of Decoder chars \t : 115\n",
      "The Longest Decoder Sample has 351 Chars\n",
      "The Longest Encoder Sample has 286 Chars\n"
     ]
    }
   ],
   "source": [
    "# getting lenghts and sizes of dataset\n",
    "num_en_chars = len(en_chars)\n",
    "num_de_chars = len(de_chars)\n",
    "\n",
    "max_en_chars_per_sample = max([len(sample) for sample in en_samples])\n",
    "max_de_chars_per_sample = max([len(sample) for sample in de_samples])\n",
    "\n",
    "num_en_samples = len(en_samples)\n",
    "num_de_samples = len(de_samples)\n",
    "\n",
    "print(f'Prabha Number of Encoder samples \\t : {num_en_samples}')\n",
    "print(f'Prabha Number of Decoder samples \\t : {num_de_samples}')\n",
    "\n",
    "print(f'Number of Encoder chars \\t : {len(en_chars)}')\n",
    "print(f'Number of Decoder chars \\t : {len(de_chars)}')\n",
    "\n",
    "print(f'The Longest Decoder Sample has {max_de_chars_per_sample} Chars')\n",
    "print(f'The Longest Encoder Sample has {max_en_chars_per_sample} Chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intializing numpy arrays to store the data to give to the seq2seq model:\n",
    "# Here we are creating numpy array with maximum encoder samples, maximum chars in all samples and num of unique chars\n",
    "encoder_input_data = np.zeros((num_en_samples,\n",
    "                               max_en_chars_per_sample,\n",
    "                               num_en_chars),\n",
    "                             dtype = 'float32')\n",
    "decoder_input_data = np.zeros((num_de_samples,\n",
    "                               max_de_chars_per_sample,\n",
    "                               num_de_chars),\n",
    "                             dtype = 'float32')\n",
    "target_data = np.zeros((num_de_samples,\n",
    "                        max_de_chars_per_sample,\n",
    "                        num_de_chars),\n",
    "                      dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step is jump into one hot representation\n",
    "'''  here we represent each sample as an array of zeros that has (n) rows and (m) columns \n",
    "    where N -> Number of character that long word has\n",
    "           M -> Number of characters that dictionary has\n",
    "'''\n",
    "# we are making embeddings for three types of data 1. Encoder Input dat, 2. Decoder Input data and 3. Target Data\n",
    "# Decoder input = \"\\tHow are you\" and Targe = \"How are you\", \\t is removed there\n",
    "for index, (en_sample,de_sample) in enumerate(zip(en_samples, de_samples)):\n",
    "    for char, en_char in enumerate(en_sample):\n",
    "        encoder_input_data[index, char, en_char_to_int[en_char]] = 1\n",
    "    for char, de_char in enumerate(de_sample):\n",
    "        decoder_input_data[index, char, de_char_to_int[en_char]] = 1\n",
    "        if char > 0:\n",
    "            target_data[index, char-1, de_char_to_int[en_char]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Encoder Input Data   : (167130, 286, 93)\n",
      "Shape of Decoder Input Data   : (167130, 351, 115)\n",
      "Shape of Target Data          : (167130, 351, 115)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of Encoder Input Data   : {encoder_input_data.shape}')\n",
    "print(f'Shape of Decoder Input Data   : {decoder_input_data.shape}')\n",
    "print(f'Shape of Target Data          : {target_data.shape}')\n",
    "\n",
    "# Now the data is ready to be used by a Seq2Seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# this is time for word processing(Using word embeddings)\n",
    "file_name = 'fra.txt'\n",
    "lines = pd.read_table(file_name, names=['en', 'de'], encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       en  \\\n",
      "0                                                     Go.   \n",
      "1                                                     Hi.   \n",
      "2                                                    Run!   \n",
      "3                                                    Run!   \n",
      "4                                                    Who?   \n",
      "5                                                    Wow!   \n",
      "6                                                   Fire!   \n",
      "7                                                   Help!   \n",
      "8                                                   Jump.   \n",
      "9                                                   Stop!   \n",
      "10                                                  Stop!   \n",
      "11                                                  Stop!   \n",
      "12                                                  Wait!   \n",
      "13                                                  Wait!   \n",
      "14                                                 Go on.   \n",
      "15                                                 Go on.   \n",
      "16                                                 Go on.   \n",
      "17                                                 Hello!   \n",
      "18                                                 Hello!   \n",
      "19                                                 I see.   \n",
      "20                                                 I try.   \n",
      "21                                                 I won!   \n",
      "22                                                 I won!   \n",
      "23                                                 I won.   \n",
      "24                                                 Oh no!   \n",
      "25                                                Attack!   \n",
      "26                                                Attack!   \n",
      "27                                                Cheers!   \n",
      "28                                                Cheers!   \n",
      "29                                                Cheers!   \n",
      "...                                                   ...   \n",
      "167100  A man who has never gone to school may steal f...   \n",
      "167101  One way to lower the number of errors in the T...   \n",
      "167102  What is old age? First you forget names, then ...   \n",
      "167103  What is old age? First you forget names, then ...   \n",
      "167104  He and I have a near-telepathic understanding ...   \n",
      "167105  Although rainforests make up only two percent ...   \n",
      "167106  She has a boyfriend she's been going out with ...   \n",
      "167107  If you translate from your second language int...   \n",
      "167108  I love trying out new things, so I always buy ...   \n",
      "167109  A good theory is characterized by the fact tha...   \n",
      "167110  The more time you spend speaking a foreign lan...   \n",
      "167111  The enquiry concluded that, despite his denial...   \n",
      "167112  The Tatoeba Project, which can be found online...   \n",
      "167113  You may not learn to speak as well as a native...   \n",
      "167114  And the good news is that today the economy is...   \n",
      "167115  E-cigarettes are being promoted as a healthy a...   \n",
      "167116  It's still too hard to find a job. And even if...   \n",
      "167117  As you contribute more sentences to the Tatoeb...   \n",
      "167118  Even at the end of the nineteenth century, sai...   \n",
      "167119  Five tremors in excess of magnitude 5.0 on the...   \n",
      "167120  No matter how much you try to convince people ...   \n",
      "167121  We need to uphold laws against discrimination ...   \n",
      "167122  A child who is a native speaker usually knows ...   \n",
      "167123  There are four main causes of alcohol-related ...   \n",
      "167124  Top-down economics never works, said Obama. \"T...   \n",
      "167125  A carbon footprint is the amount of carbon dio...   \n",
      "167126  Death is something that we're often discourage...   \n",
      "167127  Since there are usually multiple websites on a...   \n",
      "167128  If someone who doesn't know your background sa...   \n",
      "167129  It may be impossible to get a completely error...   \n",
      "\n",
      "                                                       de  \n",
      "0                                                    Va !  \n",
      "1                                                 Salut !  \n",
      "2                                                 Cours !  \n",
      "3                                                Courez !  \n",
      "4                                                   Qui ?  \n",
      "5                                              Ça alors !  \n",
      "6                                                Au feu !  \n",
      "7                                              À l'aide !  \n",
      "8                                                  Saute.  \n",
      "9                                             Ça suffit !  \n",
      "10                                                 Stop !  \n",
      "11                                           Arrête-toi !  \n",
      "12                                              Attends !  \n",
      "13                                             Attendez !  \n",
      "14                                              Poursuis.  \n",
      "15                                             Continuez.  \n",
      "16                                            Poursuivez.  \n",
      "17                                              Bonjour !  \n",
      "18                                                Salut !  \n",
      "19                                          Je comprends.  \n",
      "20                                              J'essaye.  \n",
      "21                                           J'ai gagné !  \n",
      "22                                      Je l'ai emporté !  \n",
      "23                                            J’ai gagné.  \n",
      "24                                               Oh non !  \n",
      "25                                              Attaque !  \n",
      "26                                             Attaquez !  \n",
      "27                                                Santé !  \n",
      "28                                        À votre santé !  \n",
      "29                                                Merci !  \n",
      "...                                                   ...  \n",
      "167100  Un homme qui n'a jamais été à l'école peut vol...  \n",
      "167101  Un moyen de diminuer le nombre d’erreurs dans ...  \n",
      "167102  Qu'est l'âge ? D'abord on oublie les noms, et ...  \n",
      "167103  Ce qu'est l'âge ? D'abord on oublie les noms, ...  \n",
      "167104  Lui et moi avons une compréhension quasi-télép...  \n",
      "167105  Bien que les forêts tropicales ne couvrent que...  \n",
      "167106  Elle a un copain avec qui elle sort depuis le ...  \n",
      "167107  Si vous traduisez de votre seconde langue dans...  \n",
      "167108  J'adore essayer de nouvelles choses, alors j'a...  \n",
      "167109  Une bonne théorie se caractérise par le fait d...  \n",
      "167110  Plus l'on passe de temps à parler une langue é...  \n",
      "167111  L'enquête conclut qu'en dépit de ses dénégatio...  \n",
      "167112  Le projet Tatoeba, que l'on peut trouver en li...  \n",
      "167113  Peut-être n'apprendrez-vous pas à parler comme...  \n",
      "167114  Et la bonne nouvelle est qu'aujourd'hui l'écon...  \n",
      "167115  La cigarette électronique est mise en avant co...  \n",
      "167116  C'est encore trop difficile de trouver un empl...  \n",
      "167117  Au fur et à mesure que vous ajoutez davantage ...  \n",
      "167118  Même à la fin du dix-neuvième siècle, les mari...  \n",
      "167119  Cinq secousses dépassant la magnitude cinq sur...  \n",
      "167120  Peu importe le temps que tu passeras à essayer...  \n",
      "167121  Nous devons faire respecter les lois contre la...  \n",
      "167122  Un enfant qui est un locuteur natif connaît ha...  \n",
      "167123  Il y a quatre causes principales de décès liés...  \n",
      "167124  « L'économie en partant du haut vers le bas, ç...  \n",
      "167125  Une empreinte carbone est la somme de pollutio...  \n",
      "167126  La mort est une chose qu'on nous décourage sou...  \n",
      "167127  Puisqu'il y a de multiples sites web sur chaqu...  \n",
      "167128  Si quelqu'un qui ne connaît pas vos antécédent...  \n",
      "167129  Il est peut-être impossible d'obtenir un Corpu...  \n",
      "\n",
      "[167130 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                       Go.\n",
      "1                                                       Hi.\n",
      "2                                                      Run!\n",
      "3                                                      Run!\n",
      "4                                                      Who?\n",
      "5                                                      Wow!\n",
      "6                                                     Fire!\n",
      "7                                                     Help!\n",
      "8                                                     Jump.\n",
      "9                                                     Stop!\n",
      "10                                                    Stop!\n",
      "11                                                    Stop!\n",
      "12                                                    Wait!\n",
      "13                                                    Wait!\n",
      "14                                                   Go on.\n",
      "15                                                   Go on.\n",
      "16                                                   Go on.\n",
      "17                                                   Hello!\n",
      "18                                                   Hello!\n",
      "19                                                   I see.\n",
      "20                                                   I try.\n",
      "21                                                   I won!\n",
      "22                                                   I won!\n",
      "23                                                   I won.\n",
      "24                                                   Oh no!\n",
      "25                                                  Attack!\n",
      "26                                                  Attack!\n",
      "27                                                  Cheers!\n",
      "28                                                  Cheers!\n",
      "29                                                  Cheers!\n",
      "                                ...                        \n",
      "167100    A man who has never gone to school may steal f...\n",
      "167101    One way to lower the number of errors in the T...\n",
      "167102    What is old age? First you forget names, then ...\n",
      "167103    What is old age? First you forget names, then ...\n",
      "167104    He and I have a near-telepathic understanding ...\n",
      "167105    Although rainforests make up only two percent ...\n",
      "167106    She has a boyfriend she's been going out with ...\n",
      "167107    If you translate from your second language int...\n",
      "167108    I love trying out new things, so I always buy ...\n",
      "167109    A good theory is characterized by the fact tha...\n",
      "167110    The more time you spend speaking a foreign lan...\n",
      "167111    The enquiry concluded that, despite his denial...\n",
      "167112    The Tatoeba Project, which can be found online...\n",
      "167113    You may not learn to speak as well as a native...\n",
      "167114    And the good news is that today the economy is...\n",
      "167115    E-cigarettes are being promoted as a healthy a...\n",
      "167116    It's still too hard to find a job. And even if...\n",
      "167117    As you contribute more sentences to the Tatoeb...\n",
      "167118    Even at the end of the nineteenth century, sai...\n",
      "167119    Five tremors in excess of magnitude 5.0 on the...\n",
      "167120    No matter how much you try to convince people ...\n",
      "167121    We need to uphold laws against discrimination ...\n",
      "167122    A child who is a native speaker usually knows ...\n",
      "167123    There are four main causes of alcohol-related ...\n",
      "167124    Top-down economics never works, said Obama. \"T...\n",
      "167125    A carbon footprint is the amount of carbon dio...\n",
      "167126    Death is something that we're often discourage...\n",
      "167127    Since there are usually multiple websites on a...\n",
      "167128    If someone who doesn't know your background sa...\n",
      "167129    It may be impossible to get a completely error...\n",
      "Name: en, Length: 167130, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(lines.en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to lower case\n",
    "import re\n",
    "import string\n",
    "\n",
    "lines.en = lines.en.apply(lambda x : x.lower())\n",
    "lines.de = lines.de.apply(lambda x : x.lower())\n",
    "\n",
    "# process commas\n",
    "lines.en = lines.en.apply(lambda x : re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
    "lines.de=lines.de.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
    "\n",
    "# removing punctuations\n",
    "exclude = set(string.punctuation)\n",
    "lines.en = lines.en.apply(lambda x : ''.join(char_ for char_ in x if char_ not in exclude))\n",
    "lines.de = lines.de.apply(lambda x : ''.join(char_ for char_ in x if char_ not in exclude))\n",
    "\n",
    "# getting ride of digits\n",
    "#digits = \"0123456789\"\n",
    "remove_digits = str.maketrans('', '', string.digits)\n",
    "lines.en = lines.en.apply(lambda x: x.translate(remove_digits))\n",
    "lines.de = lines.de.apply(lambda x: x.translate(remove_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample processing start from here\n",
    "# appending EOS and SOS to the target data\n",
    "# it creates these symbols for every sentence\n",
    "lines.en = lines.en.apply(lambda x : 'SOS_'+x+'_EOS')\n",
    "#print(lines.en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating word dictionaries\n",
    "en_words = set()\n",
    "for line in lines.en:\n",
    "    for word in line.split():\n",
    "        if word not in en_words:\n",
    "            en_words.add(word)\n",
    "de_words = set()\n",
    "for line in lines.de:\n",
    "    for word in line.split():\n",
    "        if word not in de_words:\n",
    "            de_words.add(word)\n",
    "# get the lengths and sizes\n",
    "# get lengths and sizes :\n",
    "num_en_words = len(en_words)\n",
    "num_de_words = len(de_words)\n",
    "\n",
    "max_en_words_per_sample = max([len(sample.split()) for sample in lines.en])+5\n",
    "max_de_words_per_sample = max([len(sample.split()) for sample in lines.de])+5\n",
    "\n",
    "num_en_samples = len(lines.en)\n",
    "num_de_samples = len(lines.de)\n",
    "\n",
    "# Get lists of words :\n",
    "input_words = sorted(list(en_words))\n",
    "target_words = sorted(list(de_words))\n",
    "\n",
    "en_token_to_int = dict()\n",
    "en_int_to_token = dict()\n",
    "\n",
    "de_token_to_int = dict()\n",
    "de_int_to_token = dict()\n",
    "\n",
    "#Tokenizing the words ( Convert them to numbers ) :\n",
    "for i,token in enumerate(input_words):\n",
    "    en_token_to_int[token] = i\n",
    "    en_int_to_token[i]     = token\n",
    "\n",
    "for i,token in enumerate(target_words):\n",
    "    de_token_to_int[token] = i\n",
    "    de_int_to_token[i]     = token\n",
    "\n",
    "# initiate numpy arrays to hold the data that our seq2seq model will use:\n",
    "encoder_input_data = np.zeros(\n",
    "    (num_en_samples, max_en_words_per_sample),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (num_de_samples, max_de_words_per_sample),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (num_de_samples, max_de_words_per_sample, num_de_words),\n",
    "    dtype='float32')\n",
    "\n",
    "# Process samples, to get input, output, target data:\n",
    "for i, (input_text, target_text) in enumerate(zip(lines.en, lines.de)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = en_token_to_int[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = de_token_to_int[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, de_token_to_int[word]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28946\n"
     ]
    }
   ],
   "source": [
    "print(len(de_token_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28946\n"
     ]
    }
   ],
   "source": [
    "print(len(decoder_target_data[len(encoder_input_data)-1][0]))\n",
    "#167129    It may be impossible to get a completely error...\n",
    "\n",
    "# print(en_int_to_token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "print(len(encoder_input_data[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "num_words = len(input_words)\n",
    "vec_len = 300\n",
    "Embedding_layer = keras.layers.Embedding(input_dim = num_words, output_dim = vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.embeddings.Embedding object at 0x11eea11668>\n"
     ]
    }
   ],
   "source": [
    "print(Embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, CuDNNLSTM,Input, Embedding, TimeDistributed, Flatten, Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Defining some constants: \n",
    "vec_len       = 300   # Length of the vector that we willl get from the embedding layer\n",
    "latent_dim    = 1024  # Hidden layers dimension \n",
    "dropout_rate  = 0.2   # Rate of the dropout layers\n",
    "batch_size    = 64    # Batch size\n",
    "epochs        = 8    # Number of epochs\n",
    "\n",
    "#Input layer of encoder\n",
    "encoder_input = Input(shape=(None,))\n",
    "\n",
    "#hidden layers of encoder\n",
    "encoder_embedding = keras.layers.Embedding(input_dim = num_en_words, output_dim = vec_len)(encoder_input)\n",
    "encoder_dropout   = (TimeDistributed(Dropout(rate= dropout_rate)))(encoder_embedding)\n",
    "encoder_LSTM      = CuDNNLSTM(latent_dim, return_sequences=True)(encoder_dropout)\n",
    "#encoder_LSTM      = LSTM(latent_dim, return_sequences=True)(encoder_dropout)\n",
    "\n",
    "# output layer of encoder\n",
    "encoder_LSTM2_layer = CuDNNLSTM(latent_dim, return_state=True)\n",
    "#encoder_LSTM2_layer = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_LSTM2_layer(encoder_LSTM)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder part , encoder states given to the decoder as first state\n",
    "decoder_input = Input(shape = (None,))\n",
    "\n",
    "#Hidden layers of decoder\n",
    "decoder_embedding_layer = keras.layers.Embedding(input_dim = num_de_words, output_dim = vec_len)\n",
    "decoder_embedding = decoder_embedding_layer(decoder_input)\n",
    "\n",
    "decoder_dropout_layer = (TimeDistributed(Dropout(rate = dropout_rate)))\n",
    "decoder_dropout = decoder_dropout_layer(decoder_embedding)\n",
    "\n",
    "decoder_LSTM_layer = CuDNNLSTM(latent_dim, return_sequences=True)\n",
    "#decoder_LSTM_layer = LSTM(latent_dim, return_sequences=True)\n",
    "decoder_LSTM = decoder_LSTM_layer(decoder_dropout, initial_state = encoder_states)\n",
    "\n",
    "decoder_LSTM_2_layer = CuDNNLSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "#decoder_LSTM_2_layer = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_LSTM_2,_,_ = decoder_LSTM_2_layer(decoder_LSTM)\n",
    "\n",
    "#output of decoder\n",
    "decoder_dense = Dense(num_de_words, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_LSTM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, None, 300), (None, 1024), (None, 1024)]\n",
      "(?, ?, 300)\n",
      "(?, ?)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_LSTM_layer.input_shape)\n",
    "print(encoder_embedding.shape)\n",
    "print(encoder_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    6522900     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 300)    0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 300)    8683800     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)        (None, None, 1024)   5431296     time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 300)    0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)        [(None, 1024), (None 8396800     cu_dnnlstm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)        (None, None, 1024)   5431296     time_distributed_2[0][0]         \n",
      "                                                                 cu_dnnlstm_2[0][1]               \n",
      "                                                                 cu_dnnlstm_2[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)        [(None, None, 1024), 8396800     cu_dnnlstm_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 28946)  29669650    cu_dnnlstm_4[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 72,532,542\n",
      "Trainable params: 72,532,542\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining the mode\n",
    "model = Model([encoder_input, decoder_input], decoder_outputs)\n",
    "\n",
    "model.summary()    # it prints a summary representation of your model.\n",
    "\n",
    "# Define a checkpoint callback :\n",
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 184 samples, validate on 16 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at /usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py:517) with these attrs: [dropout=0, seed=87654321, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at /usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py:517) ]]\n\nCaused by op 'cu_dnnlstm_1/CudnnRNN', defined at:\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 708, in __init__\n    self.run()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-2908b3f163c6>\", line 14, in <module>\n    encoder_LSTM      = CuDNNLSTM(latent_dim, return_sequences=True)(encoder_dropout)\n  File \"/usr/local/lib/python3.7/site-packages/keras/layers/recurrent.py\", line 532, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"/usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py\", line 517, in _process_batch\n    is_training=True)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1636, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1527, in __call__\n    seed=self._seed)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1014, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\", line 142, in cudnn_rnn\n    seed2=seed2, is_training=is_training, name=name)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at /usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py:517) with these attrs: [dropout=0, seed=87654321, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at /usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py:517) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by {{node cu_dnnlstm_1/CudnnRNN}}with these attrs: [dropout=0, seed=87654321, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[{{node cu_dnnlstm_1/CudnnRNN}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9291871f7356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           callbacks = callbacks_list)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 199\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at /usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py:517) with these attrs: [dropout=0, seed=87654321, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at /usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py:517) ]]\n\nCaused by op 'cu_dnnlstm_1/CudnnRNN', defined at:\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 708, in __init__\n    self.run()\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/vendor/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/Cellar/ipython/7.5.0/libexec/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-27-2908b3f163c6>\", line 14, in <module>\n    encoder_LSTM      = CuDNNLSTM(latent_dim, return_sequences=True)(encoder_dropout)\n  File \"/usr/local/lib/python3.7/site-packages/keras/layers/recurrent.py\", line 532, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"/usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py\", line 517, in _process_batch\n    is_training=True)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1636, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1527, in __call__\n    seed=self._seed)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1014, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\", line 142, in cudnn_rnn\n    seed2=seed2, is_training=is_training, name=name)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at /usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py:517) with these attrs: [dropout=0, seed=87654321, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"lstm\", is_training=true, seed2=0]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at /usr/local/lib/python3.7/site-packages/keras/layers/cudnn_recurrent.py:517) ]]\n"
     ]
    }
   ],
   "source": [
    "num_train_samples = 200\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data[:num_train_samples,:],\n",
    "               decoder_input_data[:num_train_samples,:]],\n",
    "               decoder_target_data[:num_train_samples,:,:],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.08,\n",
    "          callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = Input(shape=(None,))\n",
    "\n",
    "#hidden layers of encoder\n",
    "_embedding = keras.layers.Embedding(input_dim = num_en_words, output_dim = vec_len)\n",
    "input_ = _embedding(_input)\n",
    "p = model.predict([encoder_input_data[10], decoder_input_data[10]])\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
